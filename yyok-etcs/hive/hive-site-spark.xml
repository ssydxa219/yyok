<configuration>
    <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://10.80.58.161:3306/jianbing_hive?createDatabaseIfNotExist=true&amp;useSSL=false</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>root</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>dd@2108</value>
    </property>
    <!--<property>
    <name>hive.hwi.listen.host</name>
    <value>10.80.58.161</value>
    </property>
    <property>
    <name>hive.hwi.listen.port</name>
    <value>9999</value>
    </property>
    <property>
    <name>hive.hwi.war.file</name>
    <value>lib/hive-hwi-2.1.1.war</value>
    </property>-->
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/data/warehouse</value>
    </property>
    <property>
        <name>hive.exec.scratchdir</name>
        <value>/data/local/tmp</value>
    </property>
    <property>
        <name>hive.querylog.location</name>
        <value>/data/local/log</value>
    </property>
    <property>
        <name>hive.server2.thrift.port</name>
        <value>10000</value>
    </property>
    <property>
        <name>hive.server2.thrift.bind.host</name>
        <value>10.80.58.161</value>
    </property>
    <property>
        <name>hive.server2.webui.host</name>
        <value>10.80.58.161</value>
    </property>
    <property>
        <name>hive.server2.webui.port</name>
        <value>10002</value>
    </property>
    <property>
        <name>hive.server2.long.polling.timeout</name>
        <value>5000</value>
    </property>
    <property>
        <name>hive.server2.enable.doAs</name>
        <value>true</value>
    </property>
    <property>
        <name>datanucleus.autoCreateSchema</name>
        <value>false</value>
    </property>
    <property>
        <name>datanucleus.fixedDatastore</name>
        <value>true</value>
    </property>
    <!-- hive on mr-->
    <!--
    <property>
    <name>mapred.job.tracker</name>
    <value>http://10.80.58.161:9001</value>
    </property>
    <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
    </property>
    -->
    <!--hive on spark or spark on yarn -->
    <property>
        <name>hive.execution.engine</name>
        <value>spark</value>
    </property>
    <property>
        <name>spark.home</name>
        <value>/usr/app/spark</value>
    </property>
    <property>
        <name>spark.master</name>
        <value>spark://ddb:7077</value>
        <description>dyarn-cluster/yarn-client</description>
    </property>
    <property>
        <name>spark.submit.deployMode</name>
        <value>client</value>
    </property>
    <property>
        <name>spark.eventLog.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>spark.eventLog.dir</name>
        <value>hdfs://xinfang:9000/spark-log</value>
    </property>
    <property>
        <name>spark.serializer</name>
        <value>org.apache.spark.serializer.KryoSerializer</value>
    </property>
    <property>
        <name>spark.executor.memeory</name>
        <value>512m</value>
    </property>
    <property>
        <name>spark.driver.memeory</name>
        <value>512m</value>
    </property>
    <property>
        <name>spark.executor.extraJavaOptions</name>
        <value>-XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"</value>
    </property>
</configuration>